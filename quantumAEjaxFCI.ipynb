{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pennylane as qml\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAutoEncoder(nn.Module):\n",
    "    n_qubits: int\n",
    "    input_size: int\n",
    "    n_qlayers: int = 2\n",
    "    backend: str = \"default.qubit\"\n",
    "    embedding_dim: int = 32\n",
    "\n",
    "    def setup(self):\n",
    "        nq=self.n_qubits\n",
    "        self.dev = qml.device(self.backend, wires=nq)\n",
    "        \n",
    "        @qml.qnode(self.dev, interface='jax')\n",
    "        def circuit(x, w):\n",
    "            qml.AmplitudeEmbedding(x, wires=range(nq), normalize=True)\n",
    "            qml.templates.BasicEntanglerLayers(w, wires=range(nq))\n",
    "            result=qml.probs(wires=range(nq))#[qml.expval(qml.PauliZ(i)) for i in range(nq)]\n",
    "            return result\n",
    "        \n",
    "        def electron_constriction(x, ne, key):\n",
    "            \"\"\"\n",
    "            x: jnp.ndarray of shape (sequence_length, feature_dim, ?)\n",
    "            We will modify x[-1, :, -1]\n",
    "            ne: int, number of electrons\n",
    "            key: jax.random.PRNGKey\n",
    "            \"\"\"\n",
    "            x2 = jnp.abs(x[-1, :, -1])\n",
    "            zero_vector = jnp.zeros_like(x2)\n",
    "\n",
    "            def loop_body(i, carry):\n",
    "                x2, zero_vector, key = carry\n",
    "                key1, key2, new_key = jax.random.split(key, 3)\n",
    "\n",
    "                # ----- Even positions (alpha electrons) -----\n",
    "                x2_even = x2[::2]\n",
    "                cumsum_even = jnp.cumsum(x2_even)\n",
    "                rand_val = jax.random.uniform(key1) * cumsum_even[-1]\n",
    "                idx_even = jnp.argmax(cumsum_even >= rand_val) * 2\n",
    "\n",
    "                x2 = x2.at[idx_even].set(0.0)\n",
    "                zero_vector = zero_vector.at[idx_even].set(1.0)\n",
    "\n",
    "                # ----- Odd positions (beta electrons) -----\n",
    "                x2_odd = x2[1::2]\n",
    "                cumsum_odd = jnp.cumsum(x2_odd)\n",
    "                rand_val = jax.random.uniform(key2) * cumsum_odd[-1]\n",
    "                idx_odd = jnp.argmax(cumsum_odd >= rand_val) * 2 + 1\n",
    "\n",
    "                x2 = x2.at[idx_odd].set(0.0)\n",
    "                zero_vector = zero_vector.at[idx_odd].set(1.0)\n",
    "\n",
    "                return (x2, zero_vector, new_key)\n",
    "\n",
    "            # Loop ne//2 times\n",
    "            x2, zero_vector, key = jax.lax.fori_loop(0, ne // 2, loop_body, (x2, zero_vector, key))\n",
    "\n",
    "            # Sanity check (for debugging â€“ remove if using JIT)\n",
    "            # assert jnp.count_nonzero(zero_vector) == ne, \"Electron count mismatch\"\n",
    "\n",
    "            # Replace the last column with the constrained vector\n",
    "            x = x.at[-1, :, -1].set(zero_vector)\n",
    "\n",
    "            return x\n",
    "         \n",
    "\n",
    "        self.qnode = circuit\n",
    "        self.batched_qnode = jax.vmap(self.qnode, in_axes=(0, None))\n",
    "\n",
    "        self.weightsEnc = self.param(\n",
    "            \"weightsEnc\", nn.initializers.normal(stddev=0.1),\n",
    "            (self.n_qlayers, nq)\n",
    "        )\n",
    "        self.weightsDec = self.param(\n",
    "            \"weightsDec\", nn.initializers.normal(stddev=0.1),\n",
    "            (self.n_qlayers, nq)\n",
    "        )\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs,train: bool = True):\n",
    "        # inputs: (batch, input_size) = (16, 8)\n",
    "        x = nn.Dense(self.embedding_dim)(inputs)         \n",
    "        x = nn.relu(x)\n",
    "        x = self.batched_qnode(x, self.weightsEnc)          \n",
    "        x = nn.Dense(2 * self.embedding_dim)(x)          \n",
    "        x = nn.Dense(self.embedding_dim)(x)              \n",
    "        x = self.batched_qnode(x, self.weightsDec)          \n",
    "        x = nn.Dense(self.input_size)(x)                 # (16, 8)\n",
    "        x = self.electron_constriction(x)                                # (16, 8)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data,train_loader,test_loader,batch,epochs):\n",
    "    #print(train_data.shape)\n",
    "    #sample_input=jnp.array(train_data[16,10,8])\n",
    "    input_shape=[16,8]\n",
    "    net=QuantumAutoEncoder(n_qubits=5,input_size=8)\n",
    "    key=jax.random.PRNGKey(0)\n",
    "    params=net.init(key,jnp.ones(input_shape))\n",
    "    optimizer=optax.adam(0.01)\n",
    "    opt_state=optimizer.init(params)\n",
    "    def binary_accuracy(original, reconstructed, threshold=0.5):\n",
    "        original = jnp.array(original)\n",
    "        reconstructed = jnp.array(reconstructed)\n",
    "        pred = (reconstructed > threshold).astype(jnp.float32)\n",
    "        correct = (pred == original).astype(jnp.float32)\n",
    "        return jnp.mean(correct).item()\n",
    "    @jax.jit\n",
    "    def train_step(params,opt_state,inputs,targets):\n",
    "        def loss_fn(params,inputs,targets):\n",
    "            preds=net.apply(params,inputs)\n",
    "            loss = -jnp.mean(targets * jnp.log(preds + 1e-7) + (1 - targets) * jnp.log(1 - preds + 1e-7))\n",
    "            #jax.debug.print(\">>> preds mean: {}\", jnp.mean(preds))\n",
    "            return loss\n",
    "        loss,grad=jax.value_and_grad(loss_fn)(params,inputs,targets)\n",
    "        updates, opt_state=optimizer.update(grad,opt_state)\n",
    "        new_params=optax.apply_updates(params,updates)\n",
    "        return loss, new_params, opt_state\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data[0], data[1]\n",
    "            loss, params, opt_state = train_step(params, opt_state, inputs, targets)\n",
    "            epoch_loss += loss\n",
    "        epoch_loss /= len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {epoch_loss}\")\n",
    "        forecasted=[]\n",
    "        loss_test=[]\n",
    "        targets_val=[]\n",
    "\n",
    "    for data in test_loader:\n",
    "\n",
    "        inputs,targets=data[0],data[1]\n",
    "        preds=net.apply(params,inputs)\n",
    "        loss=-jnp.mean(targets * jnp.log(preds + 1e-7) + (1 - targets) * jnp.log(1 - preds + 1e-7))\n",
    "        \n",
    "        forecasted.append(preds)\n",
    "        targets_val.append(targets)\n",
    "        loss_test.append(loss)\n",
    "    #error metrics\n",
    "    loss_test=jnp.array(loss_test).mean()\n",
    "    print(f\"Test Loss: {loss_test}\")\n",
    "    forecasted = jnp.concatenate(forecasted, axis=0)\n",
    "    targets_val = jnp.concatenate(targets_val, axis=0)\n",
    "    print(\"Preds: mean =\", jnp.mean(forecasted), \", std =\", jnp.std(forecasted))\n",
    "    print(\"Targets: mean =\", jnp.mean(targets_val), \", std =\", jnp.std(targets_val))\n",
    "\n",
    "    accuracy = binary_accuracy(forecasted, targets_val)\n",
    "    print(f\"RMSE: {accuracy}\")\n",
    "    return net,params\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clean_data(n_samples, input_dim):\n",
    "    return np.random.randint(0, 2, (n_samples, input_dim))\n",
    "def add_noise(x, noise_level=0.2):\n",
    "    noise = np.random.randn(*x.shape) < noise_level\n",
    "    return (x + noise) % 2  # Flip bits\n",
    "def binary_accuracy(original, reconstructed, threshold=0.5):\n",
    "    pred = (reconstructed > threshold).float()\n",
    "    correct = (pred == original).float()\n",
    "    return correct.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6869564056396484\n",
      "Epoch 1, Loss: 0.6788758635520935\n",
      "Epoch 2, Loss: 0.6745942831039429\n",
      "Epoch 3, Loss: 0.6725912690162659\n",
      "Epoch 4, Loss: 0.6702226996421814\n",
      "Epoch 5, Loss: 0.669006884098053\n",
      "Epoch 6, Loss: 0.6688790917396545\n",
      "Epoch 7, Loss: 0.667693555355072\n",
      "Epoch 8, Loss: 0.6671999096870422\n",
      "Epoch 9, Loss: 0.6669465899467468\n",
      "Epoch 10, Loss: 0.6665127277374268\n",
      "Epoch 11, Loss: 0.6655364036560059\n",
      "Epoch 12, Loss: 0.6649147272109985\n",
      "Epoch 13, Loss: 0.6649458408355713\n",
      "Epoch 14, Loss: 0.6636844873428345\n",
      "Epoch 15, Loss: 0.6640265583992004\n",
      "Epoch 16, Loss: 0.6637663841247559\n",
      "Epoch 17, Loss: 0.6635016202926636\n",
      "Epoch 18, Loss: 0.6629105806350708\n",
      "Epoch 19, Loss: 0.6631539463996887\n",
      "Epoch 20, Loss: 0.6626130938529968\n",
      "Epoch 21, Loss: 0.6627051830291748\n",
      "Epoch 22, Loss: 0.6626222729682922\n",
      "Epoch 23, Loss: 0.6622732281684875\n",
      "Epoch 24, Loss: 0.6621303558349609\n",
      "Epoch 25, Loss: 0.6616784930229187\n",
      "Epoch 26, Loss: 0.6617505550384521\n",
      "Epoch 27, Loss: 0.6612953543663025\n",
      "Epoch 28, Loss: 0.6611232757568359\n",
      "Epoch 29, Loss: 0.661492109298706\n",
      "Epoch 30, Loss: 0.6612456440925598\n",
      "Epoch 31, Loss: 0.6608158349990845\n",
      "Epoch 32, Loss: 0.6607156991958618\n",
      "Epoch 33, Loss: 0.6606577038764954\n",
      "Epoch 34, Loss: 0.6608414053916931\n",
      "Epoch 35, Loss: 0.6605686545372009\n",
      "Epoch 36, Loss: 0.6602669358253479\n",
      "Epoch 37, Loss: 0.6599007844924927\n",
      "Epoch 38, Loss: 0.6598774194717407\n",
      "Epoch 39, Loss: 0.6601285934448242\n",
      "Epoch 40, Loss: 0.6600874066352844\n",
      "Epoch 41, Loss: 0.6595170497894287\n",
      "Epoch 42, Loss: 0.6597940325737\n",
      "Epoch 43, Loss: 0.6596235632896423\n",
      "Epoch 44, Loss: 0.6597995758056641\n",
      "Epoch 45, Loss: 0.6596115827560425\n",
      "Epoch 46, Loss: 0.6591800451278687\n",
      "Epoch 47, Loss: 0.6590671539306641\n",
      "Epoch 48, Loss: 0.6593238711357117\n",
      "Epoch 49, Loss: 0.6587441563606262\n",
      "Epoch 50, Loss: 0.659169614315033\n",
      "Epoch 51, Loss: 0.6590158939361572\n",
      "Epoch 52, Loss: 0.6584510803222656\n",
      "Epoch 53, Loss: 0.6585953831672668\n",
      "Epoch 54, Loss: 0.6587176322937012\n",
      "Epoch 55, Loss: 0.6582516431808472\n",
      "Epoch 56, Loss: 0.6580683588981628\n",
      "Epoch 57, Loss: 0.6583520770072937\n",
      "Epoch 58, Loss: 0.6585519909858704\n",
      "Epoch 59, Loss: 0.6580434441566467\n",
      "Epoch 60, Loss: 0.6579021215438843\n",
      "Epoch 61, Loss: 0.6578621864318848\n",
      "Epoch 62, Loss: 0.6581851243972778\n",
      "Epoch 63, Loss: 0.6577524542808533\n",
      "Epoch 64, Loss: 0.6577003002166748\n",
      "Epoch 65, Loss: 0.657715916633606\n",
      "Epoch 66, Loss: 0.6573889851570129\n",
      "Epoch 67, Loss: 0.65708988904953\n",
      "Epoch 68, Loss: 0.6575478911399841\n",
      "Epoch 69, Loss: 0.6574270725250244\n",
      "Epoch 70, Loss: 0.6569748520851135\n",
      "Epoch 71, Loss: 0.6571500897407532\n",
      "Epoch 72, Loss: 0.6574925780296326\n",
      "Epoch 73, Loss: 0.6567672491073608\n",
      "Epoch 74, Loss: 0.656979501247406\n",
      "Epoch 75, Loss: 0.656894862651825\n",
      "Epoch 76, Loss: 0.6571081280708313\n",
      "Epoch 77, Loss: 0.6569793224334717\n",
      "Epoch 78, Loss: 0.6566919684410095\n",
      "Epoch 79, Loss: 0.6564797759056091\n",
      "Epoch 80, Loss: 0.6566690802574158\n",
      "Epoch 81, Loss: 0.6567266583442688\n",
      "Epoch 82, Loss: 0.6565601229667664\n",
      "Epoch 83, Loss: 0.6561937928199768\n",
      "Epoch 84, Loss: 0.6562538743019104\n",
      "Epoch 85, Loss: 0.6564143896102905\n",
      "Epoch 86, Loss: 0.656152069568634\n",
      "Epoch 87, Loss: 0.6554823517799377\n",
      "Epoch 88, Loss: 0.6560461521148682\n",
      "Epoch 89, Loss: 0.656426727771759\n",
      "Epoch 90, Loss: 0.6560798287391663\n",
      "Epoch 91, Loss: 0.6558984518051147\n",
      "Epoch 92, Loss: 0.6555807590484619\n",
      "Epoch 93, Loss: 0.6558083891868591\n",
      "Epoch 94, Loss: 0.6554706692695618\n",
      "Epoch 95, Loss: 0.6555018424987793\n",
      "Epoch 96, Loss: 0.6557074785232544\n",
      "Epoch 97, Loss: 0.655455470085144\n",
      "Epoch 98, Loss: 0.6557421088218689\n",
      "Epoch 99, Loss: 0.6556676626205444\n",
      "Epoch 100, Loss: 0.6553280353546143\n",
      "Epoch 101, Loss: 0.655552327632904\n",
      "Epoch 102, Loss: 0.6553323268890381\n",
      "Epoch 103, Loss: 0.6556403636932373\n",
      "Epoch 104, Loss: 0.6550922989845276\n",
      "Epoch 105, Loss: 0.6552029252052307\n",
      "Epoch 106, Loss: 0.6552886962890625\n",
      "Epoch 107, Loss: 0.6550228595733643\n",
      "Epoch 108, Loss: 0.6550900340080261\n",
      "Epoch 109, Loss: 0.655218780040741\n",
      "Epoch 110, Loss: 0.6554292440414429\n",
      "Epoch 111, Loss: 0.6552014350891113\n",
      "Epoch 112, Loss: 0.6547440886497498\n",
      "Epoch 113, Loss: 0.654932975769043\n",
      "Epoch 114, Loss: 0.6549708843231201\n",
      "Epoch 115, Loss: 0.6547983288764954\n",
      "Epoch 116, Loss: 0.6551031470298767\n",
      "Epoch 117, Loss: 0.6549751162528992\n",
      "Epoch 118, Loss: 0.6545828580856323\n",
      "Epoch 119, Loss: 0.6546216011047363\n",
      "Epoch 120, Loss: 0.6548179388046265\n",
      "Epoch 121, Loss: 0.654811680316925\n",
      "Epoch 122, Loss: 0.6546798944473267\n",
      "Epoch 123, Loss: 0.6544533967971802\n",
      "Epoch 124, Loss: 0.6543585658073425\n",
      "Epoch 125, Loss: 0.6543981432914734\n",
      "Epoch 126, Loss: 0.6541731953620911\n",
      "Epoch 127, Loss: 0.6541782021522522\n",
      "Epoch 128, Loss: 0.6543681621551514\n",
      "Epoch 129, Loss: 0.6546124219894409\n",
      "Epoch 130, Loss: 0.6543231010437012\n",
      "Epoch 131, Loss: 0.6545941233634949\n",
      "Epoch 132, Loss: 0.6540542840957642\n",
      "Epoch 133, Loss: 0.6542134881019592\n",
      "Epoch 134, Loss: 0.6540139317512512\n",
      "Epoch 135, Loss: 0.6539190411567688\n",
      "Epoch 136, Loss: 0.6542019844055176\n",
      "Epoch 137, Loss: 0.653907299041748\n",
      "Epoch 138, Loss: 0.6542285084724426\n",
      "Epoch 139, Loss: 0.6538150310516357\n",
      "Epoch 140, Loss: 0.6543241143226624\n",
      "Epoch 141, Loss: 0.6538680791854858\n",
      "Epoch 142, Loss: 0.6534715294837952\n",
      "Epoch 143, Loss: 0.6537193655967712\n",
      "Epoch 144, Loss: 0.6539632678031921\n",
      "Epoch 145, Loss: 0.6539886593818665\n",
      "Epoch 146, Loss: 0.6535026431083679\n",
      "Epoch 147, Loss: 0.6536912322044373\n",
      "Epoch 148, Loss: 0.6537600755691528\n",
      "Epoch 149, Loss: 0.6536852717399597\n",
      "Test Loss: 0.6861893534660339\n",
      "Preds: mean = 0.49850237 , std = 0.13009979\n",
      "Targets: mean = 0.49739584 , std = 0.4999931\n",
      "RMSE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(QuantumAutoEncoder(\n",
       "     # attributes\n",
       "     n_qubits = 5\n",
       "     input_size = 8\n",
       "     n_qlayers = 2\n",
       "     backend = 'default.qubit'\n",
       "     embedding_dim = 32\n",
       " ),\n",
       " {'params': {'Dense_0': {'bias': Array([-0.9148683 ,  2.2726054 ,  2.1679316 , -1.5716857 , -0.66860855,\n",
       "            1.397078  ,  0.15520507,  1.2170259 , -0.2107089 , -1.9452105 ,\n",
       "            1.4254565 , -2.117494  ,  2.8563974 , -1.8062284 , -1.4366468 ,\n",
       "            2.577079  ,  0.7471307 , -1.7303091 ,  0.02512974,  0.8536879 ,\n",
       "           -3.5370615 , -1.2477065 ,  1.2060643 , -2.3516333 ,  1.9831634 ,\n",
       "            0.14551745, -0.36467347, -0.7905444 ,  1.1378888 , -0.18673113,\n",
       "            1.0532075 , -1.349688  ], dtype=float32),\n",
       "    'kernel': Array([[ 1.16617098e-01,  3.77709717e-01, -9.35216546e-01,\n",
       "             3.38628078e+00, -1.60734951e+00, -1.19939864e+00,\n",
       "            -3.95994592e+00, -6.06687427e-01, -6.54238462e-02,\n",
       "             5.52972615e-01, -4.50445986e+00, -4.09472942e+00,\n",
       "             2.12708235e+00, -1.80171561e+00, -9.56900656e-01,\n",
       "            -2.00598097e+00, -2.00929976e+00, -9.49264646e-01,\n",
       "            -5.71040571e-01, -2.54583430e+00, -4.09418440e+00,\n",
       "            -6.70806110e-01, -2.63648748e+00,  1.68690860e+00,\n",
       "            -3.52656507e+00,  2.98766947e+00, -1.98336852e+00,\n",
       "            -1.05677724e+00, -2.91970110e+00,  2.18551517e+00,\n",
       "            -2.50632715e+00, -7.56553710e-01],\n",
       "           [-3.12840295e+00, -2.58780026e+00, -4.10502052e+00,\n",
       "             4.10093307e+00, -4.70037997e-01,  2.53002614e-01,\n",
       "             7.78323472e-01, -1.71555459e+00, -1.12434052e-01,\n",
       "            -2.08490896e+00, -3.62568164e+00,  2.82431781e-01,\n",
       "            -1.18361667e-01,  2.54861522e+00,  1.62773120e+00,\n",
       "            -2.99481773e+00, -2.91493440e+00, -5.41352318e-04,\n",
       "            -3.02987194e+00, -4.53472823e-01,  1.22636288e-01,\n",
       "             4.19467878e+00,  9.54772174e-01,  1.15035808e+00,\n",
       "             3.10113668e+00, -1.33372867e+00,  1.35737872e+00,\n",
       "            -1.14841831e+00,  1.69571519e-01, -4.72821116e-01,\n",
       "             1.49215209e+00,  1.20719142e-01],\n",
       "           [ 2.98709178e+00,  4.00669527e+00, -3.24302363e+00,\n",
       "            -1.85870457e+00,  9.63774204e-01, -3.00911999e+00,\n",
       "             4.03097010e+00, -2.47367287e+00,  4.99166071e-01,\n",
       "            -3.50215286e-01,  1.11015773e+00, -1.63517797e+00,\n",
       "            -1.17001247e+00,  1.11627150e+00, -1.87966549e+00,\n",
       "             2.16158450e-01, -3.45780778e+00,  2.57175732e+00,\n",
       "            -1.22614348e+00,  1.66015291e+00,  1.01359379e+00,\n",
       "             2.30944872e+00, -3.79057527e+00, -8.95078838e-01,\n",
       "            -2.46624446e+00, -1.61779284e+00,  2.22203076e-01,\n",
       "            -3.91483814e-01, -1.15692210e+00, -2.03688288e+00,\n",
       "             9.47712213e-02,  1.05740809e+00],\n",
       "           [-3.01537538e+00,  1.58609915e+00,  3.97733760e+00,\n",
       "             7.16925383e-01, -4.19149017e+00,  1.42663372e+00,\n",
       "             8.90237629e-01,  2.41208625e+00,  3.75471997e+00,\n",
       "             2.78699088e+00,  1.50052655e+00, -9.30821076e-02,\n",
       "            -3.06688714e+00,  1.11412323e+00,  3.08849931e+00,\n",
       "             3.48326176e-01,  2.85697746e+00,  5.63939571e-01,\n",
       "            -1.26691731e-02,  3.17115337e-01, -2.46988401e-01,\n",
       "             2.67715693e+00, -6.58156574e-01,  9.18631077e-01,\n",
       "             8.93493220e-02,  3.09836745e+00,  2.43856859e+00,\n",
       "            -5.85325778e-01, -1.41326869e+00, -2.37580895e+00,\n",
       "            -1.71311235e+00, -3.73500919e+00],\n",
       "           [-1.83668816e+00, -1.53759909e+00, -7.61436224e-01,\n",
       "             2.73030686e+00,  3.56708622e+00, -2.49690747e+00,\n",
       "            -1.54692578e+00,  1.78034627e+00,  2.66605449e+00,\n",
       "            -1.84985018e+00,  2.13568807e+00,  3.39594722e+00,\n",
       "            -2.42719364e+00, -2.55912566e+00, -1.15195155e-01,\n",
       "            -2.41625595e+00, -1.22321117e+00,  1.06334829e+00,\n",
       "            -8.13253284e-01, -1.68209493e+00,  1.93729019e+00,\n",
       "            -8.66489932e-02, -4.39866066e-01, -4.30876684e+00,\n",
       "            -1.22247314e+00, -2.88236570e+00, -1.62771344e+00,\n",
       "            -7.46438578e-02, -2.12256694e+00, -4.82076287e-01,\n",
       "             2.42292857e+00,  3.10716301e-01],\n",
       "           [ 1.25172663e+00, -3.88100624e-01,  5.31156600e-01,\n",
       "             1.47127390e-01, -9.41569984e-01, -2.31181836e+00,\n",
       "             8.26948702e-01, -2.09343743e+00,  4.27640319e-01,\n",
       "             1.48777914e+00, -2.04173827e+00,  2.48102963e-01,\n",
       "            -8.04678082e-01, -1.57173455e-01,  1.98309171e+00,\n",
       "             3.80278349e+00,  1.35830939e+00, -3.39039040e+00,\n",
       "             2.09359026e+00,  7.80184448e-01,  3.39462686e+00,\n",
       "            -6.31482780e-01, -6.38405025e-01,  1.83674192e+00,\n",
       "            -5.28551161e-01, -2.93871880e+00,  2.38803005e+00,\n",
       "            -3.97322297e+00,  5.25528669e-01,  1.44472718e+00,\n",
       "            -3.47803783e+00,  4.63985205e+00],\n",
       "           [ 1.16482341e+00,  9.05429482e-01,  1.03482139e+00,\n",
       "            -1.16061121e-01,  7.96591997e-01,  2.76453757e+00,\n",
       "            -1.32560670e+00, -1.14758420e+00, -2.92487288e+00,\n",
       "             2.62851810e+00, -4.40851301e-01,  4.46960306e+00,\n",
       "            -2.67870426e+00,  2.05659246e+00, -9.92711782e-01,\n",
       "            -3.06494737e+00, -8.53887320e-01, -2.81551623e+00,\n",
       "            -3.42283034e+00, -2.67694950e+00,  2.12630004e-01,\n",
       "             7.81795025e-01,  3.08625555e+00, -1.99697703e-01,\n",
       "             2.44117165e+00, -9.45920348e-01,  1.95773911e+00,\n",
       "             4.71026564e+00, -2.34564328e+00,  2.09315777e+00,\n",
       "            -1.48202610e+00, -2.43093699e-01],\n",
       "           [ 1.31071103e+00, -3.69052863e+00,  1.05093074e+00,\n",
       "             6.64514363e-01, -2.03883743e+00,  2.80328155e+00,\n",
       "            -2.08868289e+00, -1.08978844e+00, -7.39323869e-02,\n",
       "            -1.22783875e+00, -1.75899196e+00, -3.98194522e-01,\n",
       "            -2.90633154e+00, -5.11041284e-01, -2.76031399e+00,\n",
       "             1.96472430e+00,  7.01129436e-01,  3.50378799e+00,\n",
       "             1.64332199e+00, -3.03770518e+00,  5.29340446e-01,\n",
       "             1.40115654e+00, -3.55147219e+00,  1.26271105e+00,\n",
       "             1.70196283e+00, -5.14003217e-01, -1.72364330e+00,\n",
       "             9.61315155e-01,  2.54242563e+00, -2.74932528e+00,\n",
       "            -3.73436189e+00, -4.68178225e+00]], dtype=float32)},\n",
       "   'Dense_1': {'bias': Array([ 0.19296466,  0.09349995,  0.15637799, -0.05983757, -0.0726456 ,\n",
       "            0.01814575,  0.00575523, -0.04597849,  0.00374196, -0.54101926,\n",
       "            0.09829358,  0.08112364,  0.15553713,  0.04877652,  0.29956567,\n",
       "            0.38838965, -0.13013819, -0.07522135, -0.00293004,  0.31297436,\n",
       "            0.14609416,  0.20368148,  0.15473469,  0.07499972, -0.03694184,\n",
       "            0.06956252,  0.17226827,  0.38796747, -0.02583804,  0.27136508,\n",
       "            0.08912371, -0.44375378, -0.09560446, -0.32946384, -0.09090577,\n",
       "           -0.00397856, -0.02904234,  0.70308554, -0.09045754,  0.11288646,\n",
       "           -0.01509001, -0.04160017,  0.12989074,  0.27040803,  0.35768223,\n",
       "            0.15065703, -0.03283948, -0.19409153,  0.17657916,  0.10504784,\n",
       "           -0.01008289, -0.06735141,  0.0708091 , -0.05084055, -0.36385098,\n",
       "            0.05033801, -0.1161138 , -0.18627658, -0.09100349,  0.05775397,\n",
       "            0.13590434,  0.31127194,  0.20382328, -0.10483347], dtype=float32),\n",
       "    'kernel': Array([[-3.2998877 , -5.010395  ,  0.8671328 , ..., -3.6581726 ,\n",
       "             0.7222947 ,  4.001656  ],\n",
       "           [-0.52170485, -0.7265542 , -1.2402412 , ...,  3.1090431 ,\n",
       "             0.29892915, -0.87798536],\n",
       "           [ 1.0169683 , -0.4361211 ,  1.474512  , ...,  0.5559012 ,\n",
       "            -3.0973222 ,  1.0372504 ],\n",
       "           ...,\n",
       "           [ 1.3381523 , -1.767334  ,  5.4932375 , ..., -0.9439748 ,\n",
       "             5.5011706 ,  0.33929628],\n",
       "           [ 5.690923  ,  3.6791596 ,  2.3680768 , ..., -1.3424464 ,\n",
       "            -5.414815  , -3.008035  ],\n",
       "           [-1.4454219 ,  0.8809071 , -1.6857493 , ...,  2.9484804 ,\n",
       "            -2.876475  ,  0.38018793]], dtype=float32)},\n",
       "   'Dense_2': {'bias': Array([ 2.4550722 ,  1.217206  , -3.2112994 , -0.73924416,  1.2014135 ,\n",
       "           -1.8085515 , -1.7185278 ,  1.268859  , -1.8590617 , -2.4846067 ,\n",
       "           -3.2155845 , -1.2887613 ,  2.3099792 , -2.0721166 , -1.6880723 ,\n",
       "            2.375992  ,  2.2379897 ,  1.9278177 , -2.479347  ,  1.3685815 ,\n",
       "            1.8044862 , -0.42654127,  0.02653476, -2.4484317 ,  0.8794689 ,\n",
       "           -1.5811183 ,  1.7786059 ,  0.19540705,  2.1180294 , -0.9251884 ,\n",
       "            2.4389963 , -3.5162768 ], dtype=float32),\n",
       "    'kernel': Array([[-0.6682123 ,  0.5035406 , -3.3976517 , ...,  1.4366723 ,\n",
       "            -2.088417  , -1.6455393 ],\n",
       "           [-0.5065399 ,  0.33669385, -1.0832661 , ...,  4.504323  ,\n",
       "            -1.5319189 , -1.5592554 ],\n",
       "           [-1.1200646 ,  3.7976625 , -0.70929265, ...,  0.03745079,\n",
       "             3.9800935 ,  1.3247616 ],\n",
       "           ...,\n",
       "           [ 0.9716266 , -0.4023603 , -1.1620796 , ..., -3.0082603 ,\n",
       "             0.8563543 ,  0.6666492 ],\n",
       "           [ 0.36733577,  1.5868657 ,  0.8916622 , ..., -0.396073  ,\n",
       "             2.8416834 ,  1.6063553 ],\n",
       "           [ 1.4473983 ,  0.36663437,  0.3847252 , ..., -2.4032018 ,\n",
       "            -1.0721031 ,  1.8370769 ]], dtype=float32)},\n",
       "   'Dense_3': {'bias': Array([ 0.08164831, -0.02898991, -0.29192907, -0.11539955, -0.11602344,\n",
       "           -0.0838664 ,  0.02878688,  0.15624218], dtype=float32),\n",
       "    'kernel': Array([[-9.3171326e-03,  6.4853370e-01,  1.2731090e+00,  1.3328968e+00,\n",
       "             2.9117274e-01, -1.3015521e+00, -1.5170916e+00,  4.6189895e+00],\n",
       "           [ 1.6155362e+00,  3.0438459e+00,  2.2683458e+00,  1.6980401e+00,\n",
       "            -5.2367979e-01,  6.0436291e-01, -6.3363063e-01,  8.5664481e-01],\n",
       "           [-3.7768419e+00, -2.3980525e+00,  1.0160344e+00,  6.9474763e-01,\n",
       "             1.0162338e+00, -2.9871092e+00,  2.5171163e+00,  5.3944111e-01],\n",
       "           [-8.1732988e-01,  1.6563270e+00, -2.3340189e+00, -2.9214313e+00,\n",
       "            -8.0532151e-01, -3.5425243e+00, -4.3005009e+00,  4.8108059e-01],\n",
       "           [ 1.5998331e+00,  2.8594468e+00, -7.8121817e-01,  8.1203336e-01,\n",
       "             1.7079022e+00, -4.2608616e-01, -1.4930737e-02, -4.5833249e+00],\n",
       "           [ 9.1948020e-01,  3.6571365e-02,  3.2655776e+00, -9.4265354e-01,\n",
       "             6.0412025e-01,  3.1969392e+00, -9.1605175e-01, -5.0467402e-01],\n",
       "           [ 2.9335973e+00, -1.9621921e+00, -1.8870292e+00, -1.8630883e+00,\n",
       "             4.2193753e-01, -4.0311699e+00,  2.4311443e-01,  3.0430107e+00],\n",
       "           [-1.5743080e+00, -1.6881330e+00, -2.5450442e+00,  4.1511316e+00,\n",
       "            -1.3294556e+00, -5.0790024e-01, -3.1770223e-01, -4.3861194e+00],\n",
       "           [-3.9935040e+00, -7.1724081e-01,  3.4534328e+00,  2.7652452e+00,\n",
       "            -8.4658511e-02,  2.5121042e-01, -2.0903203e+00, -7.3496354e-01],\n",
       "           [-2.2009697e-02, -1.9276822e+00,  9.2992705e-01, -8.6813366e-01,\n",
       "             8.6342412e-01, -3.1358378e+00, -2.5867066e-01,  1.4096889e+00],\n",
       "           [ 1.4204634e+00,  5.7119722e+00,  8.2090044e-01,  2.7986330e-01,\n",
       "            -2.6980622e+00,  2.1532292e+00,  7.3298663e-01, -1.5632256e+00],\n",
       "           [ 4.0346923e+00, -2.4340830e+00,  1.7221106e+00,  5.9180025e-02,\n",
       "            -1.5153375e+00,  2.8333783e-02, -3.2201447e+00,  6.4525336e-01],\n",
       "           [-6.9059336e-01,  3.4518700e+00, -2.8107870e-01,  5.0002879e-01,\n",
       "            -7.6176947e-01, -3.5138519e+00,  4.3826776e+00,  1.1143472e+00],\n",
       "           [-2.7520235e+00,  8.5009739e-02, -2.1501982e+00,  2.1506371e+00,\n",
       "             1.8806181e+00,  3.4741981e+00, -2.2416201e+00,  3.1226056e+00],\n",
       "           [-1.2193242e+00,  2.6385909e-01, -1.3034828e+00, -1.6173536e+00,\n",
       "             1.4652742e+00, -7.3069103e-02, -2.5678585e+00, -2.5842001e+00],\n",
       "           [-1.1144911e-01,  2.7124703e-01,  2.3340530e+00, -4.1985445e+00,\n",
       "             2.8503501e+00,  2.1051333e+00,  3.0542762e+00,  7.9750401e-01],\n",
       "           [ 8.5254437e-01,  2.1382709e+00, -1.3392648e+00, -6.5897234e-02,\n",
       "            -2.2495351e+00,  5.6098547e+00, -1.3838584e+00,  9.7885907e-01],\n",
       "           [-1.5102798e+00, -1.2813904e+00, -5.9379530e-01, -1.4969733e+00,\n",
       "            -3.6875992e+00,  6.4445668e-01,  7.2453439e-01,  1.8411261e+00],\n",
       "           [-5.7861573e-01, -7.8675985e-02, -1.5130851e-01,  5.5049424e+00,\n",
       "             3.2170172e+00,  1.6269797e+00,  4.3080080e-01,  2.0809395e+00],\n",
       "           [ 1.5177494e+00, -2.8367752e-01, -2.1556647e+00,  1.9640236e+00,\n",
       "             5.6000367e-02, -2.8216994e-01,  1.4329075e+00,  5.7655180e-01],\n",
       "           [ 9.3016952e-01, -5.7437944e-01,  2.7798051e-01,  3.0625153e+00,\n",
       "             4.1270375e+00, -1.6312685e+00, -3.4956152e+00, -1.7769022e-01],\n",
       "           [-4.6404195e-01, -1.3395860e+00,  1.5543828e+00, -2.2618697e+00,\n",
       "             3.2648814e+00,  2.3213980e+00,  1.6685448e+00, -1.0397547e+00],\n",
       "           [ 3.5018890e+00,  3.2178564e+00, -1.2568370e+00,  5.6067353e-01,\n",
       "            -2.9893771e-01,  1.4294184e+00,  5.3183708e+00,  2.4887314e+00],\n",
       "           [-2.4530621e+00,  2.6857977e+00, -2.7798409e+00, -2.3036857e+00,\n",
       "            -2.8090706e-01,  7.2550762e-01,  2.2453871e+00, -1.5297619e+00],\n",
       "           [-3.0020511e-01, -2.2401321e+00,  4.0189633e+00,  1.2160944e+00,\n",
       "            -3.6983693e+00,  1.3886528e+00,  3.2854629e+00, -2.6704409e+00],\n",
       "           [ 1.7069708e+00,  3.5247867e+00,  4.7424736e+00,  1.6150421e+00,\n",
       "            -9.1684687e-01, -2.9352264e+00, -1.2099155e+00, -1.5748768e+00],\n",
       "           [ 2.4491849e+00, -2.9581432e+00, -1.8194813e+00,  6.1986220e-01,\n",
       "             3.9340029e+00,  5.7746500e-01, -1.0714074e+00, -1.9290837e+00],\n",
       "           [ 1.6408073e+00, -1.6353285e+00, -1.6560973e-01, -2.3645954e+00,\n",
       "            -2.5639534e+00,  4.0052012e-01, -4.2038590e-01, -9.8946422e-01],\n",
       "           [ 8.8875204e-01, -1.1385330e-01, -1.0709465e+00,  1.1177144e+00,\n",
       "             3.8341369e-02, -2.0083672e-01, -4.5123608e-03,  9.4050938e-01],\n",
       "           [-1.1317698e+00,  6.4014144e-02,  3.1815583e-01, -2.0001991e+00,\n",
       "            -2.1173187e-01,  8.8729031e-02,  8.2456964e-01, -2.1623707e+00],\n",
       "           [-1.5234787e+00,  3.8379753e-01, -1.1540549e+00,  3.2179949e+00,\n",
       "            -5.2849805e-01, -2.7261269e+00,  1.1080677e-01, -3.5636095e-04],\n",
       "           [ 2.0357108e+00, -6.3219137e+00, -1.0612582e+00,  1.4607708e+00,\n",
       "             3.1276131e+00,  3.2392091e-01,  2.9746284e+00, -7.2597569e-01]],      dtype=float32)},\n",
       "   'weightsDec': Array([[-0.08885465, -0.11649495,  0.06946871, -0.05166307,  0.03772616],\n",
       "          [-0.17076291,  0.00823589, -0.17603451, -0.05340866, -0.130036  ]],      dtype=float32),\n",
       "   'weightsEnc': Array([[ 0.07357009,  0.0255939 , -0.00890782,  0.1278226 , -0.06405798],\n",
       "          [-0.05077432,  0.03008091,  0.08444447, -0.00292779,  0.09679624]],      dtype=float32)}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax_dataloader as jdl\n",
    "noise_level=0.3\n",
    "input_size=8\n",
    "batch_size=16\n",
    "samples=batch_size*300\n",
    "clean_data = generate_clean_data(samples, input_size)\n",
    "noisy_data = add_noise(clean_data, noise_level=noise_level)\n",
    "train_data=jdl.ArrayDataset(clean_data,noisy_data)\n",
    "train_loader=jdl.DataLoader(train_data,backend='jax',batch_size=16,shuffle=True,drop_last=True)\n",
    "test_samples = generate_clean_data(96, input_size)\n",
    "noisy_test = add_noise(test_samples, noise_level=0.3)\n",
    "test_data=jdl.ArrayDataset(test_samples,noisy_test)\n",
    "test_loader=jdl.DataLoader(test_data,backend='jax',batch_size=16,shuffle=False,drop_last=True)\n",
    "train_model(clean_data,train_loader,test_loader,batch_size,epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
